---
layout: post
title: Project 2 Reflection
---

Site: [https://mjung5.github.io/online-news-prediction/](https://mjung5.github.io/online-news-prediction/)

Repo: [https://github.com/mjung5/online-news-prediction](https://github.com/mjung5/online-news-prediction)

For this project, we analyzed the 'online news popularity' dataset and created 4 models to predict the number of shares an article would receive.
To make our models more robust, data was split on channel type (tech, lifestyle, entertainment, etc.) and models were built exclusively with data from each channel.

One of the hardest things for this project was the model building. When building the linear model, we tried many different variables but acheived very low
r^2 values. One thing that helped us acheive better scores was taking the log of the response variable. Looking back, the dataset contained outliers --
many of the articles had a few dozen shares, but there were a handfull of articles that had thousands of shares. I think these articles greatly influenced 
our linear models and are the reason for low r^2 scores. In the future, I think it would be smart to train models where outliers are ommitted from training data.

One of the big takeaways from this assignment is that it is hard to predict characteristics of text-based content. The dataset we recieved contained many numerical
attributes of articles. However, we are still far off from using computers to understand text and using statistics to predict the success of text. These observations 
follow the observations of NLP projects I have contributed to in the past.
